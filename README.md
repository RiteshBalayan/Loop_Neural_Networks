# Theory of Intelligence: Dynamic Memory Instances in Neural Networks

![Neural Network](https://img.shields.io/badge/Neural-Network-blue)
![Python](https://img.shields.io/badge/Language-Python-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

This repository contains the implementation and experimentation of the Theory of Intelligence proposed in the thesis titled "Theory of Intelligence and Simulation of Memory Instances". The theory introduces a novel approach to neural network memory, modeling dynamic memory connections through loops of current.

## Overview

The essence of the theory lies in representing memory instances within neural networks as loops of current, inspired by the dynamics of biological neural systems. These loops serve as the basis for forming dynamic memory connections, facilitating adaptive learning and information retention akin to human memory processes.

## Implementation

### Python Notebook

The `theory_of_intelligence.ipynb` notebook provides a comprehensive overview of the implementation and training process for abstract memory instances on custom neural networks. It demonstrates the formation of Bayesian basis for memory in intelligent neural networks, showcasing the dynamic interplay of memory loops in learning tasks.

### Requirements

- Python 3.x
- NumPy
- Matplotlib
- Jupyter Notebook

### Usage

1. Clone the repository:

```
git clone https://github.com/yourusername/theory-of-intelligence.git
```

2. Navigate to the repository directory:

```
cd theory-of-intelligence
```

3. Launch the Jupyter Notebook:

```
jupyter notebook theory_of_intelligence.ipynb
```

4. Follow the instructions provided in the notebook to explore the implementation and experimentation of dynamic memory instances in neural networks.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgements

- This research is self funded by author.

